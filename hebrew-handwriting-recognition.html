<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hebrew Cursive Letters Recognition</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="logo-container">
            <a href="#top" class="logo-link">
                <h1>Hanna Fettaya</h1>
            </a>
        </div>
        <nav class="nav-links">
            <a href="#about">About</a>
            <a href="#workflow">Workflow</a>
            <a href="#results">Results</a>
            <a href="#resources">Resources</a>
        </nav>
    </header>
    
    <main>
        <section id="about" class="about-section">
            <h2>About the Project</h2>
            <p>
                This project aims to classify handwritten Hebrew cursive letters using deep learning models, specifically comparing a traditional Convolutional Neural Network (CNN) with transfer learning approaches. The dataset includes 5,073 labeled images representing 27 distinct Hebrew letters.
            </p>
            <ul>
                <li>Baseline CNN model built from scratch with regularization techniques.</li>
                <li>Transfer learning with pre-trained models: ResNet50 and VGG16.</li>
            </ul>
        </section>

        <section id="workflow" class="project-detail">
            <h2>Workflow and Techniques</h2>

            <h3>1. Data Preprocessing</h3>
            <p>
                Images were resized and normalized. Labels were one-hot encoded and the dataset was split into training, validation, and test sets. Data augmentation was used to expand the dataset and reduce overfitting.
            </p>

            <h3>2. CNN Model (from scratch)</h3>
            <ul>
                <li>Implemented regularization (L1/L2), dropout, and early stopping.</li>
                <li>Used data augmentation with horizontal/vertical flips and zoom.</li>
                <li>Model achieved 67% accuracy.</li>
            </ul>

            <h3>3. Transfer Learning</h3>
            <p>
                Pre-trained models (ResNet50, VGG16) were fine-tuned for the classification task:
            </p>
            <ul>
                <li><strong>ResNet50:</strong> Fine-tuned using learning rate 0.001 and Adam optimizer — accuracy reached 80%.</li>
                <li><strong>VGG16:</strong> Achieved best performance with 82% accuracy using similar hyperparameters.</li>
            </ul>
        </section>

        <section id="results" class="project-detail">
            <h2>Results and Insights</h2>
            <p>
                Transfer learning models significantly outperformed the traditional CNN:
            </p>
            <ul>
                <li><strong>VGG16</strong> achieved the highest accuracy: 82%.</li>
                <li>Fine-tuning deeper layers improved generalization.</li>
                <li>Some letters were visually similar and frequently misclassified.</li>
            </ul>
            <p>Future improvements could include testing other architectures (EfficientNet, Inception), using larger datasets, or hyperparameter optimization.</p>
        </section>

        <section id="resources" class="project-detail">
            <h2>Resources</h2>
            <ul>
                <li><a href="https://github.com/HannaOuanounou/Recognition-of-Handwritten-Hebrew-letters-with-Transfer-Learning" target="_blank">GitHub Repository</a></li>
                <li><a href="https://colab.research.google.com/github/HannaOuanounou/Recognition-of-Handwritten-Hebrew-letters-with-Transfer-Learning/blob/main/Recognition_of_Handwritten_Hebrew_letters_with_Transfer_Learning.ipynb" target="_blank">Open in Google Colab</a></li>
            </ul>
        </section>
    </main>

    <footer>
        <p>© 2024 Hanna Fettaya. All rights reserved.</p>
    </footer>
</body>
</html>
